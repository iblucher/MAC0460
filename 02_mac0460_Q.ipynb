{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivos\n",
    "\n",
    "Implementar e testar a solu√ß√£o anal√≠tica para o problema de regress√£o linear \n",
    "\n",
    "Este notebook depende de m√≥dulos auxiliares que est√£o na pasta util/ mais alguns imports do Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress√£o linear: equa√ß√µes normais\n",
    "\n",
    "\n",
    "Dado um dataset $\\{(\\mathbf{x}_{1}, y_{1}), \\dots ,(\\mathbf{x}_{N}, y_{N})\\}$ onde $\\mathbf{x}_i \\in \\mathbb{R}^{d}$ e $y_i \\in \\mathbb{R}$, queremos aproximar a fun√ß√£o desconhecida $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (lembrando que $y_i =f(\\mathbf{x}_i)$) por meio de um modelo linear $h$:\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}_{i} + b\n",
    "$$\n",
    "\n",
    "Note que $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ √© na verdade uma [transforma√ß√£o afim](https://en.wikipedia.org/wiki/Affine_transformation) de $\\mathbf{x}_{i}$. Como em outros lugares, vamos usar o termo \"linear\" tamb√©m para caracterizar uma transforma√ß√£o afim.\n",
    "\n",
    "A sa√≠da de $h$ √© uma transforma√ß√£o linear de $\\mathbf{x}_{i}$. Usamos a nota√ß√£o $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ para deixar claro que $h$ √© um modelo parametrizado, i.e., a transforma√ß√£o $h$ √© definida pelos par√¢metros $\\mathbf{w}$ e $b$. Podemos pensar no vetor $\\mathbf{w}$ como um vetor de *pesos* controlando o efeito de cada *feature* na predi√ß√£o.\n",
    "\n",
    "Adicionando uma feature a mais na obseva√ß√£o $\\mathbf{x}_{i}$ (com o valor 1) -- coordenada artificial -- podemos simplificar a nota√ß√£o do modelo:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}) = \\hat{y}_{i} = \\mathbf{w}^\\top  \\mathbf{x}_{i}\n",
    "$$\n",
    "\n",
    "Gostar√≠amos de encontrar os melhores par√¢metros $\\mathbf{w}$ de modo que a predi√ß√£o $\\hat{y}_{i}$ seja a mais pr√≥xima de $y_{i}$ de acordo com alguma m√©trica de erro. Usando o *erro quadr√°rico m√©dio* como tal m√©trica podemos obter a seguinte fun√ß√£o de custo:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}(\\hat{y}_{i} - y_{i})^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Desse modo, a tarefa de achar a fun√ß√£o $h$ mais pr√≥xima de $f$ se torna a tarefa de encontrar os valores de $\\mathbf{w}$ para minimizar $J(\\mathbf{w})$.\n",
    "\n",
    "**Aqui vamos come√ßar a explorar esse modelo olhando para um dataset bem simples**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import numpy as np\n",
    "import time\n",
    "from util.util import get_housing_prices_data, r_squared\n",
    "from util.plots import plot_points_regression \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O dataset\n",
    "\n",
    "Os dados que vamos trabalhar s√£o dados artificiais. Iremos gerar 100 observa√ß√µes com apenas uma *feature* e um valor asociado a cada uma delas. Podemos interpretar essas observa√ß√µes como sendo um par *(metros quadrados de um im√≥vel, pre√ßo desse im√≥vel em $)*. Nossa tarefa √© construir um modelo que consiga predizer o valor dos im√≥veis, dadas as suas √°reas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando os dados\n",
    "\n",
    "Acima temos algumas informa√ß√µes sobre os dados. Podemos tamb√©m visualizar cada ponto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equa√ß√µes normais\n",
    "\n",
    "Dados $f:\\mathbb{R}^{n\\times m} \\rightarrow \\mathbb{R}$ e $\\mathbf{A} \\in \\mathbb{R}^{n\\times m}$, definimos o gradiente de $f$ com respeito a $\\mathbf{A}$ como:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f = \\frac{\\partial f}{\\partial \\mathbf{A}} =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Seja $\\mathbf{X} \\in \\mathbb{R}^{N\\times m}$ a matriz cujas linhas s√£o as observa√ß√µes do dataset (tamb√©m chamada de *design matrix*) e seja $\\mathbf{y} \\in \\mathbb{R}^{N}$ o vetor contendo todos os valores de $y_{i}$ (i.e., $\\mathbf{X}_{i,:} = \\mathbf{x}_{i}$ e $\\mathbf{y}_{i} =y_{i}$). √â f√°cil checar que: \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Usando certos conceitos b√°sicos de derivada com matrizes podemos chegar no gradiente de $J(\\mathbf{w})$ com respeito a $\\mathbf{w}$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Assim, quando $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ temos que \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Desse modo,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "A solu√ß√£o dada por essas equa√ß√µes s√£o conhecidas como **equa√ß√µes normais**. Note que esse tipo de solu√ß√£o tem um custo, pois conforme cresce o n√∫mero de vari√°veis, o tempo da invers√£o da matriz fica proibitivo. Vale a pena ler [esse material](http://cs229.stanford.edu/notes/cs229-notes1.pdf) para ver o argumento com mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exerc√≠cio\n",
    "Usando apenas a biblioteca **NumPy** (uma introdu√ß√£o r√°pida a certas funcionalidades dessa biblioteca pode ser encontrada [aqui](http://cs231n.github.io/python-numpy-tutorial/)), complete as duas fun√ß√µes abaixo. Lembre que $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$; assim, ser√° preciso adicionar uma componente com valor 1 a cada observa√ß√£o em $\\mathbf{X}$ para realizar a computa√ß√£o descrita acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_weights(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the weights of a linear function using the normal equation method.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: weight vector\n",
    "    :rtype: np.ndarray(shape=(d+1, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    raise NotImplementedError(\"Falta implementar normal_equation_weights()\")\n",
    "    # END YOUR CODE\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste da fun√ß√£o normal_equation_weights()\n",
    "\n",
    "w = 0  # isto √© desnecess√°rio\n",
    "w = normal_equation_weights(X, y)\n",
    "print(\"Estimated w = \", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, w):\n",
    "    \"\"\"\n",
    "    Calculates the prediction over a set of observations X using the linear function\n",
    "    characterized by the weight vector w.\n",
    "    You should add into X a new column with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param w: weight vector\n",
    "    :type w: np.ndarray(shape=(d+1, 1))\n",
    "    :param y: regression prediction\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # START OF YOUR CODE:\n",
    "    raise NotImplementedError(\"Falta implementar normal_equation_prediction()\")\n",
    "    # END YOUR CODE\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Voc√™ pode usar a m√©trica [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) para ver o qu√£o bem o modelo linear est√° se ajustando aos dados.\n",
    "\n",
    "**Nesse caso $ùëÖ^2$ tem que estar pr√≥ximo de 0.5.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste da fun√ß√£o normal_equation_prediction()\n",
    "prediction = normal_equation_prediction(X, w)\n",
    "r_2 = r_squared(y, prediction)\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testes adicionais\n",
    "\n",
    "Vamos fazer a predi√ß√£o para $x=650$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando a fun√ß√£o de predi√ß√£o\n",
    "x = np.asarray([650]).reshape(1,1)\n",
    "prediction = normal_equation_prediction(x, w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x[0], prediction))\n",
    "\n",
    "# de forma mais direta\n",
    "y = np.dot(np.asarray((1,x)), w)\n",
    "print(\"Area = %.2f  Predicted price = %.4f\" %(x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efeito do n√∫mero de amostras e dimens√£o dos dados\n",
    "\n",
    "Varie o n√∫mero de amostras $N$ e veja como varia o tempo de processamento.\n",
    "\n",
    "Teste o seu c√≥digo para dados nos quais $ùëë>1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para diferentes valores de N\n",
    "X, y = get_housing_prices_data(N=1000000)\n",
    "init = time.time()\n",
    "w = normal_equation_weights(X, y)\n",
    "prediction = normal_equation_prediction(X,w)\n",
    "init = time.time() - init\n",
    "\n",
    "print(\"Tempo de execu√ß√£o = {:.8f}(s)\".format(init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste para dados de dimens√£o d>1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
